{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988107b-4c97-414d-8d20-2f0f10b68c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "INPUT_CSV = \"mentions_retraction_fill.csv\"\n",
    "\n",
    "COLUMNS_TO_DELETE = [\n",
    "    \"External Mention ID\",\n",
    "    \"Authors at my Institution\",\n",
    "    \"Departments\",\n",
    "    \"ISBN\",\n",
    "    \"National Clinical Trial ID\",\n",
    "    \"URI\",\n",
    "    \"Handle.net IDs\",\n",
    "    \"ADS Bibcode\",\n",
    "    \"arXiv ID\",\n",
    "    \"RePEc ID\",\n",
    "    \"SSRN\",\n",
    "    \"URN\",\n",
    "    \"error\",\n",
    "    \"text_len\",\n",
    "    \"extraction_method\",\n",
    "    \"text_truncated\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    INPUT_CSV,\n",
    "    dtype=str,\n",
    "    keep_default_na=False,\n",
    "    na_values=[]\n",
    ")\n",
    "\n",
    "orig_rows = len(df)\n",
    "deduped_df = df.drop_duplicates(keep=\"first\")\n",
    "dup_removed = orig_rows - len(deduped_df)\n",
    "\n",
    "work = deduped_df.copy()\n",
    "if \"text_len_full\" not in work.columns:\n",
    "    raise KeyError(\"Missing column 'text_len_full'. Please ensure it exists in the file.\")\n",
    "\n",
    "num = pd.to_numeric(work[\"text_len_full\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "zero_mask = (num == 0)\n",
    "zero_len_count = int(zero_mask.sum())\n",
    "\n",
    "small_mask = (num < 200) & (~zero_mask)\n",
    "small_len_count = int(small_mask.sum())\n",
    "\n",
    "work = work[~(num < 200)].copy()\n",
    "final_rows = len(work)\n",
    "\n",
    "def find_col(cols, target):\n",
    "    target_lower = target.strip().lower()\n",
    "    for c in cols:\n",
    "        if c.strip().lower() == target_lower:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "norm_url_col = find_col(work.columns, \"norm_url\")\n",
    "if norm_url_col is None:\n",
    "    raise KeyError(\"Missing column 'norm_url' (case or space may differ). Please verify the file.\")\n",
    "\n",
    "unique_norm_url_count = work[norm_url_col].nunique(dropna=True)\n",
    "\n",
    "def normalize(name: str) -> str:\n",
    "    return name.strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "norm_map = {normalize(c): c for c in work.columns}\n",
    "to_delete_norm = [normalize(x) for x in COLUMNS_TO_DELETE]\n",
    "\n",
    "existing_to_drop = []\n",
    "missing_to_drop = []\n",
    "for n in to_delete_norm:\n",
    "    if n in norm_map:\n",
    "        existing_to_drop.append(norm_map[n])\n",
    "    else:\n",
    "        n2 = n.replace(\".\", \"\").replace(\"-\", \"\")\n",
    "        matched = None\n",
    "        for k, v in norm_map.items():\n",
    "            if k.replace(\".\", \"\").replace(\"-\", \"\") == n2:\n",
    "                matched = v\n",
    "                break\n",
    "        if matched:\n",
    "            existing_to_drop.append(matched)\n",
    "        else:\n",
    "            missing_to_drop.append(n)\n",
    "\n",
    "existing_to_drop = sorted(set(existing_to_drop), key=lambda x: work.columns.get_loc(x))\n",
    "work = work.drop(columns=existing_to_drop, errors=\"ignore\")\n",
    "\n",
    "print(\"===== Cleaning Statistics =====\")\n",
    "print(f\"Original total rows: {orig_rows}\")\n",
    "print(f\"Removed identical duplicate rows: {dup_removed}\")\n",
    "print(f\"Removed rows where text_len_full == 0: {zero_len_count}\")\n",
    "print(f\"Removed rows where 0 < text_len_full < 200: {small_len_count}\")\n",
    "print(f\"Final total rows: {final_rows}\")\n",
    "print(f\"Unique norm_url count: {unique_norm_url_count}\")\n",
    "\n",
    "print(\"\\n===== Column Removal Results =====\")\n",
    "print(\"Deleted columns (actual names):\", existing_to_drop if existing_to_drop else \"None\")\n",
    "if missing_to_drop:\n",
    "    print(\"Not found (normalized names, may differ due to naming variations):\", missing_to_drop)\n",
    "\n",
    "base, ext = os.path.splitext(INPUT_CSV)\n",
    "output_csv = f\"{base}_cleaned{ext or '.csv'}\"\n",
    "work.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nCleaned file saved as: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee0f76-b416-40b8-b645-12946bbce79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "INPUT_CSV = \"mentions_retraction_fill.csv\"\n",
    "\n",
    "COLUMNS_TO_DELETE = [\n",
    "    \"External Mention ID\",\n",
    "    \"Authors at my Institution\",\n",
    "    \"Departments\",\n",
    "    \"ISBN\",\n",
    "    \"National Clinical Trial ID\",\n",
    "    \"URI\",\n",
    "    \"Handle.net IDs\",\n",
    "    \"ADS Bibcode\",\n",
    "    \"arXiv ID\",\n",
    "    \"RePEc ID\",\n",
    "    \"SSRN\",\n",
    "    \"URN\",\n",
    "    \"error\",\n",
    "    \"text_len\",\n",
    "    \"extraction_method\",\n",
    "    \"text_truncated\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    INPUT_CSV,\n",
    "    dtype=str,\n",
    "    keep_default_na=False,\n",
    "    na_values=[]\n",
    ")\n",
    "\n",
    "orig_rows = len(df)\n",
    "deduped_df = df.drop_duplicates(keep=\"first\")\n",
    "dup_removed = orig_rows - len(deduped_df)\n",
    "\n",
    "work = deduped_df.copy()\n",
    "if \"text_len_full\" not in work.columns:\n",
    "    raise KeyError(\"Missing column 'text_len_full'. Please ensure it exists in the file.\")\n",
    "\n",
    "num = pd.to_numeric(work[\"text_len_full\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "zero_mask = (num == 0)\n",
    "zero_len_count = int(zero_mask.sum())\n",
    "\n",
    "small_mask = (num < 200) & (~zero_mask)\n",
    "small_len_count = int(small_mask.sum())\n",
    "\n",
    "work = work[~(num < 200)].copy()\n",
    "final_rows = len(work)\n",
    "\n",
    "def find_col(cols, target):\n",
    "    target_lower = target.strip().lower()\n",
    "    for c in cols:\n",
    "        if c.strip().lower() == target_lower:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "norm_url_col = find_col(work.columns, \"norm_url\")\n",
    "if norm_url_col is None:\n",
    "    raise KeyError(\"Missing column 'norm_url' (case or space may differ). Please verify the file.\")\n",
    "\n",
    "unique_norm_url_count = work[norm_url_col].nunique(dropna=True)\n",
    "\n",
    "def normalize(name: str) -> str:\n",
    "    return name.strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "norm_map = {normalize(c): c for c in work.columns}\n",
    "to_delete_norm = [normalize(x) for x in COLUMNS_TO_DELETE]\n",
    "\n",
    "existing_to_drop = []\n",
    "missing_to_drop = []\n",
    "for n in to_delete_norm:\n",
    "    if n in norm_map:\n",
    "        existing_to_drop.append(norm_map[n])\n",
    "    else:\n",
    "        n2 = n.replace(\".\", \"\").replace(\"-\", \"\")\n",
    "        matched = None\n",
    "        for k, v in norm_map.items():\n",
    "            if k.replace(\".\", \"\").replace(\"-\", \"\") == n2:\n",
    "                matched = v\n",
    "                break\n",
    "        if matched:\n",
    "            existing_to_drop.append(matched)\n",
    "        else:\n",
    "            missing_to_drop.append(n)\n",
    "\n",
    "existing_to_drop = sorted(set(existing_to_drop), key=lambda x: work.columns.get_loc(x))\n",
    "work = work.drop(columns=existing_to_drop, errors=\"ignore\")\n",
    "\n",
    "print(\"===== Cleaning Statistics =====\")\n",
    "print(f\"Original total rows: {orig_rows}\")\n",
    "print(f\"Removed identical duplicate rows: {dup_removed}\")\n",
    "print(f\"Removed rows where text_len_full == 0: {zero_len_count}\")\n",
    "print(f\"Removed rows where 0 < text_len_full < 200: {small_len_count}\")\n",
    "print(f\"Final total rows: {final_rows}\")\n",
    "print(f\"Unique norm_url count: {unique_norm_url_count}\")\n",
    "\n",
    "print(\"\\n===== Column Removal Results =====\")\n",
    "print(\"Deleted columns (actual names):\", existing_to_drop if existing_to_drop else \"None\")\n",
    "if missing_to_drop:\n",
    "    print(\"Not found (normalized names, may differ due to naming variations):\", missing_to_drop)\n",
    "\n",
    "base, ext = os.path.splitext(INPUT_CSV)\n",
    "output_csv = f\"{base}_cleaned{ext or '.csv'}\"\n",
    "work.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nCleaned file saved as: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
