{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e53b922-f901-4d2c-95bb-bd133cc2d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/miaoyixuan/CS58/timeline_classified_outputs\n",
      "{'original_before': (14532, 46), 'original_after_exclusive': (6378, 46), 'original_after_comention': (8078, 46), 'retraction_before_exclusive': (361, 46), 'retraction_before_comention': (1902, 46), 'retraction_after': (12729, 46)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PATH_MASTER = \"dataset_14_08_2025_completion.csv\"\n",
    "PATH_ORIG   = \"mentions_original_fill_cleaned.csv\"\n",
    "PATH_RETR   = \"mentions_retraction_fill_cleaned.csv\"\n",
    "OUT = Path(\"timeline_classified_outputs\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "def norm_str(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    x = str(x).strip()\n",
    "    return np.nan if x in {\"\", \"0\", \"nan\", \"NaN\", \"none\", \"None\", \"null\", \"Null\"} else x\n",
    "\n",
    "def norm_doi(x):\n",
    "    x = norm_str(x)\n",
    "    if pd.isna(x): return np.nan\n",
    "    x = x.lower()\n",
    "    if x.startswith(\"doi:\"):\n",
    "        x = x[4:].strip()\n",
    "    return x\n",
    "\n",
    "def canonical_url(x):\n",
    "    x = norm_str(x)\n",
    "    if pd.isna(x): return np.nan\n",
    "    x = x.strip()\n",
    "    if \"#\" in x:\n",
    "        x = x.split(\"#\", 1)[0]\n",
    "    return x\n",
    "\n",
    "master = pd.read_csv(PATH_MASTER, dtype=str, keep_default_na=False)\n",
    "for c in [\"OriginalPaperDate\",\"RetractionDate\"]:\n",
    "    master[c] = pd.to_datetime(master[c], errors=\"coerce\", utc=True)\n",
    "\n",
    "master[\"orig_doi_norm\"] = master.get(\"OriginalPaperDOI\").map(norm_doi)\n",
    "master[\"retr_doi_norm\"] = master.get(\"RetractionDOI\").map(norm_doi)\n",
    "\n",
    "map_origdoi_to_retrdate = (\n",
    "    master.dropna(subset=[\"orig_doi_norm\",\"RetractionDate\"])\n",
    "          .groupby(\"orig_doi_norm\")[\"RetractionDate\"].min()\n",
    ")\n",
    "map_retrdoi_to_retrdate = (\n",
    "    master.dropna(subset=[\"retr_doi_norm\",\"RetractionDate\"])\n",
    "          .groupby(\"retr_doi_norm\")[\"RetractionDate\"].min()\n",
    ")\n",
    "\n",
    "orig_full = pd.read_csv(PATH_ORIG, dtype=str, keep_default_na=False)\n",
    "retr_full = pd.read_csv(PATH_RETR, dtype=str, keep_default_na=False)\n",
    "\n",
    "orig_cols = orig_full.columns.tolist()\n",
    "retr_cols = retr_full.columns.tolist()\n",
    "\n",
    "orig = orig_full.copy()\n",
    "retr = retr_full.copy()\n",
    "\n",
    "for df in (orig, retr):\n",
    "    df[\"Mention Date\"] = pd.to_datetime(df[\"Mention Date\"], errors=\"coerce\", utc=True)\n",
    "    df[\"DOI\"] = df[\"DOI\"].map(norm_doi)\n",
    "    df[\"Mention URL\"] = df[\"Mention URL\"].map(canonical_url)\n",
    "\n",
    "orig[\"RetractionDate_mapped\"] = orig[\"DOI\"].map(map_origdoi_to_retrdate)\n",
    "retr[\"RetractionDate_mapped\"] = retr[\"DOI\"].map(map_retrdoi_to_retrdate)\n",
    "\n",
    "orig[\"delay_days\"] = (orig[\"Mention Date\"] - orig[\"RetractionDate_mapped\"]).dt.days\n",
    "retr[\"delay_days\"] = (retr[\"Mention Date\"] - retr[\"RetractionDate_mapped\"]).dt.days\n",
    "\n",
    "orig_valid = orig[orig[\"delay_days\"].notna()].copy()\n",
    "retr_valid = retr[retr[\"delay_days\"].notna()].copy()\n",
    "\n",
    "urls_orig_all = set(orig_valid[\"Mention URL\"].dropna())\n",
    "urls_retr_all = set(retr_valid[\"Mention URL\"].dropna())\n",
    "\n",
    "mask_o_before = orig_valid[\"delay_days\"] < 0\n",
    "mask_o_after  = orig_valid[\"delay_days\"] >= 0\n",
    "\n",
    "mask_o_after_comention = mask_o_after & orig_valid[\"Mention URL\"].isin(urls_retr_all)\n",
    "mask_o_after_exclusive = mask_o_after & ~orig_valid[\"Mention URL\"].isin(urls_retr_all)\n",
    "\n",
    "mask_r_before = retr_valid[\"delay_days\"] < 0\n",
    "mask_r_after  = retr_valid[\"delay_days\"] >= 0\n",
    "\n",
    "mask_r_before_comention = mask_r_before & retr_valid[\"Mention URL\"].isin(urls_orig_all)\n",
    "mask_r_before_exclusive = mask_r_before & ~retr_valid[\"Mention URL\"].isin(urls_orig_all)\n",
    "\n",
    "original_before = orig_valid[mask_o_before]\n",
    "original_before[orig_cols].to_csv(OUT/\"original_before.csv\", index=False)\n",
    "\n",
    "original_after_exclusive = orig_valid[mask_o_after_exclusive]\n",
    "original_after_exclusive[orig_cols].to_csv(OUT/\"original_after_exclusive.csv\", index=False)\n",
    "\n",
    "original_after_comention = orig_valid[mask_o_after_comention]\n",
    "original_after_comention[orig_cols].to_csv(OUT/\"original_after_comention.csv\", index=False)\n",
    "\n",
    "retraction_before_exclusive = retr_valid[mask_r_before_exclusive]\n",
    "retraction_before_exclusive[retr_cols].to_csv(OUT/\"retraction_before_exclusive.csv\", index=False)\n",
    "\n",
    "retraction_before_comention = retr_valid[mask_r_before_comention]\n",
    "retraction_before_comention[retr_cols].to_csv(OUT/\"retraction_before_comention.csv\", index=False)\n",
    "\n",
    "retraction_after = retr_valid[mask_r_after]\n",
    "retraction_after[retr_cols].to_csv(OUT/\"retraction_after.csv\", index=False)\n",
    "\n",
    "print(\"Saved to:\", OUT.resolve())\n",
    "print({\n",
    "    \"original_before\": original_before.shape,\n",
    "    \"original_after_exclusive\": original_after_exclusive.shape,\n",
    "    \"original_after_comention\": original_after_comention.shape,\n",
    "    \"retraction_before_exclusive\": retraction_before_exclusive.shape,\n",
    "    \"retraction_before_comention\": retraction_before_comention.shape,\n",
    "    \"retraction_after\": retraction_after.shape,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd03d83-b5b2-4f8c-8052-5ffc7f5d268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Potential Misinformation Keyword Filtering Summary ===\n",
      "Original After-Retraction (exclusive): 6,378 rows\n",
      " → Without keywords: 3,718 (58.29% of group, 12.68% of full original CSV)\n",
      "Retraction Before-Retraction (exclusive): 361 rows\n",
      " → Without keywords: 70 (19.39% of group, 0.45% of full retraction CSV)\n",
      "Outputs saved to: /Users/miaoyixuan/CS58/keyword_filtered_outputs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"timeline_classified_outputs\")   \n",
    "PATH_ORIG_AFTER_EXCL = BASE / \"original_after_exclusive.csv\"\n",
    "PATH_RETR_BEFORE_EXCL = BASE / \"retraction_before_exclusive.csv\"\n",
    "\n",
    "PATH_ORIG_FULL = \"mentions_original_fill_cleaned.csv\"\n",
    "PATH_RETR_FULL = \"mentions_retraction_fill_cleaned.csv\"\n",
    "\n",
    "orig_after_excl = pd.read_csv(PATH_ORIG_AFTER_EXCL, dtype=str, keep_default_na=False)\n",
    "retr_before_excl = pd.read_csv(PATH_RETR_BEFORE_EXCL, dtype=str, keep_default_na=False)\n",
    "orig_full = pd.read_csv(PATH_ORIG_FULL, dtype=str, keep_default_na=False)\n",
    "retr_full = pd.read_csv(PATH_RETR_FULL, dtype=str, keep_default_na=False)\n",
    "\n",
    "keywords = [\n",
    "    \"retraction\", \"retracted\", \"withdrawn\", \"scandal\", \"controversial\",\n",
    "    \"fake\", \"fraud\", \"error\", \"misconduct\", \"correction\", \"corrupted\"\n",
    "]\n",
    "pattern = re.compile(\"|\".join(keywords), flags=re.IGNORECASE)\n",
    "\n",
    "def filter_no_keywords(df):\n",
    "    mention_col = df.get(\"Mention Title\", \"\")\n",
    "    output_col = df.get(\"Research Output Title\", \"\")\n",
    "    combined = mention_col.astype(str) + \" \" + output_col.astype(str)\n",
    "    mask_no_kw = ~combined.str.contains(pattern, na=False)\n",
    "    return df[mask_no_kw]\n",
    "\n",
    "orig_no_kw = filter_no_keywords(orig_after_excl)\n",
    "retr_no_kw = filter_no_keywords(retr_before_excl)\n",
    "\n",
    "OUT = Path(\"keyword_filtered_outputs\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "orig_no_kw.to_csv(OUT / \"original_after_exclusive_no_keywords.csv\", index=False)\n",
    "retr_no_kw.to_csv(OUT / \"retraction_before_exclusive_no_keywords.csv\", index=False)\n",
    "\n",
    "orig_total = len(orig_after_excl)\n",
    "retr_total = len(retr_before_excl)\n",
    "orig_no_kw_n = len(orig_no_kw)\n",
    "retr_no_kw_n = len(retr_no_kw)\n",
    "\n",
    "orig_ratio = orig_no_kw_n / orig_total * 100 if orig_total else 0\n",
    "retr_ratio = retr_no_kw_n / retr_total * 100 if retr_total else 0\n",
    "\n",
    "orig_ratio_vs_full = orig_no_kw_n / len(orig_full) * 100\n",
    "retr_ratio_vs_full = retr_no_kw_n / len(retr_full) * 100\n",
    "\n",
    "print(\"=== Potential Misinformation Keyword Filtering Summary ===\")\n",
    "print(f\"Original After-Retraction (exclusive): {orig_total:,} rows\")\n",
    "print(f\" → Without keywords: {orig_no_kw_n:,} ({orig_ratio:.2f}% of group, {orig_ratio_vs_full:.2f}% of full original CSV)\")\n",
    "\n",
    "print(f\"Retraction Before-Retraction (exclusive): {retr_total:,} rows\")\n",
    "print(f\" → Without keywords: {retr_no_kw_n:,} ({retr_ratio:.2f}% of group, {retr_ratio_vs_full:.2f}% of full retraction CSV)\")\n",
    "\n",
    "print(f\"Outputs saved to: {OUT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50d220-e28d-4f10-b355-566ad45c9213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
